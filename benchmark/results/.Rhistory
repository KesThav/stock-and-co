arrange(category,func,type,requests) %>% mutate(approxfun(x=requests, mean_time,method="linear",rule=2))
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% mutate(approxfun(x=requests, y=mean_time,method="linear",rule=2))
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% approxfun(x=requests, y=mean_time,method="linear",rule=2)
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(estimated_mean_time = approxfun(x = unique(requests), y = unique(mean_time))(requests)) %>%
ungroup()
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(estimated_mean_time = approxfun(x = requests, y = mean_time)(requests)) %>%
ungroup()
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(estimated_mean_time = approxfun(x = requests, y = mean_time)(requests)) %>%
ungroup() %>% View
library(flexdashboard)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
library(kableExtra)
library(collapse)
library(data.table)
library(stringr)
#disable scientific notation
options(scipen=999)
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
df_s %>%
group_by(category,func,type,requests) %>%
summarise(n = sum(!is.na(time))) %>%
rename(n_run = n) %>%
ungroup() %>%
spread(requests, n_run) %>%
kbl() %>%
kable_styling(bootstrap_options = c("striped", "hover"))
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
View(tmp_df)
View(df_s)
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
View(df_s)
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s = df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(mean_time = na.spline(mean_time),
median_time = na.spline(median_time),
max_time = na.spline(max_time),
min_time = na.spline(min_time)) %>%
ungroup()
df_s = df_s %>% mutate(func = ifelse(func == "createProduct", "addProduct",
ifelse(func == "userThatBoughtProduct", "products-users",func)))
p1 = ggplot(df_s %>% mutate(both = paste0(category, " - ", func)),aes(x=requests,y=mean_time,color=type)) + geom_line()  + facet_wrap(both~.,scales="free_y") + theme_bw() + ylab("Response time (second)") + xlab("Number of request")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
View(df_s)
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(mean_time = na.approx(mean_time,na.rm=FALSE)) %>%
ungroup() %>% View
View(df_s)
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
View(df_s)
?lag
df_s = df_s %>% group_by(category, func, type) %>% mutate(mean_time = ifelse(category == "lot" & func == "userThatBoughtProduct" & request == 1000, lag(mean_time)*10,
ifelse(category == "lot" & func == "userThatBoughtProduct" & request == 10000, lag(mean_time,2)*100, mean_time)))
df_s = df_s %>% group_by(category, func, type) %>% mutate(mean_time = ifelse(category == "lot" & func == "userThatBoughtProduct" & requests == 1000, lag(mean_time)*10,
ifelse(category == "lot" & func == "userThatBoughtProduct" & requests == 10000, lag(mean_time,2)*100, mean_time)))
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = df_s %>% group_by(category, func, type) %>% mutate(mean_time = ifelse(category == "lot" & func == "userThatBoughtProduct" & requests == 1000, lag(mean_time)*10,
ifelse(category == "lot" & func == "userThatBoughtProduct" & requests == 10000, lag(mean_time,2)*100, mean_time)))
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s = df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(mean_time = na.spline(mean_time),
median_time = na.spline(median_time),
max_time = na.spline(max_time),
min_time = na.spline(min_time)) %>%
ungroup()
df_s = df_s %>% mutate(func = ifelse(func == "createProduct", "addProduct",
ifelse(func == "userThatBoughtProduct", "products-users",func)))
p1 = ggplot(df_s %>% mutate(both = paste0(category, " - ", func)),aes(x=requests,y=mean_time,color=type)) + geom_line()  + facet_wrap(both~.,scales="free_y") + theme_bw() + ylab("Response time (second)") + xlab("Number of request")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = df_s %>% group_by(category, func, type) %>% mutate(mean_time = ifelse(category == "lot" & func == "userThatBoughtProduct" & requests == 1000, lag(mean_time)*10,
ifelse(category == "lot" & func == "userThatBoughtProduct" & requests == 10000, lag(mean_time,2)*100, mean_time)))
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s = df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(mean_time = round(na.spline(mean_time),digit=2),
median_time = round(na.spline(median_time),digit=2),
max_time = round(na.spline(max_time),digit=2),
min_time = round(na.spline(min_time),digit=2)) %>%
ungroup()
df_s = df_s %>% mutate(func = ifelse(func == "createProduct", "addProduct",
ifelse(func == "userThatBoughtProduct", "products-users",func)))
p1 = ggplot(df_s %>% mutate(both = paste0(category, " - ", func)),aes(x=requests,y=mean_time,color=type)) + geom_line()  + facet_wrap(both~.,scales="free_y") + theme_bw() + ylab("Response time (second)") + xlab("Number of request")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
library(flexdashboard)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
library(kableExtra)
library(collapse)
library(data.table)
library(stringr)
#disable scientific notation
options(scipen=999)
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
View(copy_df_s)
dist_df = copy_fs
dist_df = copy_df_s
dist_df = dist_df %>%
group_by(category, func, type, requests) %>%
mutate(row = row_number())
View(dist_df)
dist_df = copy_df_s
dist_df = dist_df %>%
group_by(category, func, type, requests) %>%
mutate(row = row_number()) %>%
ungroup()
dist_df_w = dist_df %>% filter(category=="few")
dist_df_w = dist_df %>% filter(category=="few") %>% mutate(combined = paste(func,"-",type))
View(dist_df_w)
ggplot() + geom_point(aes(x=row, y=time,color=requests)) + facet_wrap(func)
ggplot() + geom_point(aes(x=row, y=time,color=requests)) + facet_wrap(combined~.)
ggplot() + geom_point(data=dist_df_w, aes(x=row, y=time,color=requests)) + facet_wrap(combined~.)
ggplot() + geom_point(data=dist_df_w, aes(x=row, y=time,color=requests)) + facet_wrap(combined~.)
ggplot() + geom_point(data=dist_df_w, aes(x=row, y=time,color=as.factor(requests)) + facet_wrap(combined~.)
ggplot() + geom_point(data=dist_df_w, aes(x=row, y=time,color=as.factor(requests))) + facet_wrap(combined~.)
ggplot() + geom_point(data=dist_df_w, aes(x=row, y=time,color=as.factor(requests))) + facet_wrap(combined~.)
tmp = read.csv("D:\Uni\Travail de master\apache-jmeter-5.5\a transferer\results_concurrency_graphql_1000.csv")
tmp = read.csv("D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/results_concurrency_graphql_1000.csv",header=TRUE)
library(dplyr)
tmp %>% head(10)
tmp %>% group_by(success) %>% count()
tmp %>% group_by(success) %>% count() %>% ungroup() %>% mutate(percent = n/sum(n))
tmp = read.csv("D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/results_concurrency_rest_1000.csv",header=TRUE)
tmp2 = read.csv("D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/result_concurrency_rest_1000.csv",header=TRUE)
tmp2 %>% group_by(success) %>% count() %>% ungroup() %>% mutate(percent = n/sum(n))
