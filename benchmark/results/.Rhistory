df_s_f %>% filter(func == userThatBoughtProduct)
df_s_f %>% filter(func == "userThatBoughtProduct")
df_s_f %>% filter(func == "userThatBoughtProduct") %>% View
df_s_f %>% filter(func == "userThatBoughtProduct") %>% count()
df_s_f <- df_s_f %>%
group_by(func,type) %>%
arrange(func,type,requests) %>%
mutate(times = na.spline(time)) %>%
ungroup() %>%
mutate(times = ifelse(func == "userThatBoughtProduct" & request > 1000, NA, times))
df_s_f <- df_s_f %>%
group_by(func,type) %>%
arrange(func,type,requests) %>%
mutate(times = na.spline(time)) %>%
ungroup() %>%
mutate(times = ifelse(func == "userThatBoughtProduct" & requests > 1000, NA, times))
ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + facet_grid(.~func)
ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + facet_grid(.~func,scales="free")
ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + facet_wrap(.~func,scales="free_y")
ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + facet_wrap(.~func,scales="free")
ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + facet_wrap(.~func,scales="free_x")
p = ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + facet_wrap(.~func,scales="free_y") + theme_bw()
ggplot(p)
ggplotly(p)
View(copy_df_s_f)
p = ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + geom_boxplot(copy_df_s_f,x=requests,y=time) facet_wrap(.~func,scales="free_y") + theme_bw()
p = ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + geom_boxplot(copy_df_s_f,x=requests,y=time) + facet_wrap(.~func,scales="free_y") + theme_bw()
p = ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + geom_boxplot(copy_df_s_f,aes(x=requests,y=time)) + facet_wrap(.~func,scales="free_y") + theme_bw()
p = ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + geom_boxplot(data=copy_df_s_f,aes(x=requests,y=time)) + facet_wrap(.~func,scales="free_y") + theme_bw()
ggplotly(p)
p = ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line() + geom_boxplot(data=copy_df_s_f,aes(x=requests,y=time)) + facet_wrap(func~.,scales="free_y") + theme_bw()
ggplotly(p)
p = ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line()  + facet_wrap(func~.,scales="free_y") + theme_bw()
ggplotly(p)
copy_df_s_f %>% mutate(requests = as.factor(requests)) %>% ggplot() + geom_boxplot(.,aes(x=requests,y=time))
copy_df_s_f %>% mutate(requests = as.factor(requests)) %>% ggplot(data=.) + geom_boxplot(aes(x=requests,y=time))
copy_df_s_f %>% mutate(requests = as.factor(requests)) %>% ggplot(data=.) + geom_boxplot(aes(x=requests,y=time)) + facet_wrap(func~.)
copy_df_s_f %>% mutate(requests = as.factor(requests)) %>% ggplot(data=.) + geom_boxplot(aes(x=requests,y=time,color=type)) + facet_wrap(func~.)
copy_df_s_f %>% mutate(requests = as.factor(requests)) %>% ggplot(data=.) + geom_boxplot(aes(x=requests,y=time,color=type)) + facet_wrap(func~.,scales="free_y")
copy_df_s_f %>% mutate(requests = as.factor(requests)) %>% ggplot(data=.) + geom_boxplot(aes(x=requests,y=time,color=type)) + facet_wrap(func~.,scales="free_y") + theme_bw()
copy_df_s_f %>% mutate(requests = as.factor(requests)) %>% ggplot(data=.) + geom_boxplot(aes(x=requests,y=time,color=type)) + facet_wrap(func~.,scales="free_y") + theme_bw() %>% ggplotly(.)
p1 = ggplot(df_s_f,aes(x=requests,y=times,color=type)) + geom_line()  + facet_wrap(func~.,scales="free_y") + theme_bw()
ggplotly(p1)
p2 = copy_df_s_f %>% mutate(requests = as.factor(requests)) %>% ggplot(data=.) + geom_boxplot(aes(x=requests,y=time,color=type)) + facet_wrap(func~.,scales="free_y") + theme_bw()
ggplotly(p2)
p2
p1
ggplotly(p1)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
#disable scientific notation
options(scipen=999)
############################################# Concurrent ##############################################################################################
#load json files and transform them
df_c <- data.frame()
files = c("concurrent_createProduct_GraphQL",
"concurrent_createProduct_REST",
"concurrent_getProductBoughtByUser_GraphQL",
"concurrent_getProductBoughtByUser_REST",
"concurrent_getUsers_REST",
"concurrent_getUsers_GraphQL")
for(file in files){
print(file)
data <- fromJSON(paste0("concurrent/",file,".json"))
data <- bind_rows(data, .id = 'concurrent_user')
data['type'] = file
df_c = rbind(df_c,data)
}
rm(data)
df_c = do.call(data.frame,df_c)
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",3:5) %>%
group_by(type, concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(.~type) + theme_bw()
ggplotly(p)
df_c <- data.frame()
files = c("concurrent_createProduct_GraphQL",
"concurrent_createProduct_REST",
"concurrent_getProductBoughtByUser_GraphQL",
"concurrent_getProductBoughtByUser_REST",
"concurrent_getUsers_REST",
"concurrent_getUsers_GraphQL")
for(file in files){
print(file)
data <- fromJSON(paste0("concurrent/",file,".json"))
data <- bind_rows(data, .id = 'concurrent_user')
data['type'] = file
df_c = rbind(df_c,data)
}
rm(data)
df_c = do.call(data.frame,df_c)
df_c = df_c %>% tidyr::separate(data = .,col = type,sep = "_",into = c("to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove"))
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup()
View(p)
View(p)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:6) %>%
group_by(type, concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(.~type) + theme_bw()
ggplotly(p)
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:6) %>%
group_by(type, concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(func~type) + theme_bw()
ggplotly(p)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:6) %>%
group_by(type, func,concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(func~type) + theme_bw()
ggplotly(p)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
#disable scientific notation
options(scipen=999)
############################################# Concurrent ##############################################################################################
#load json files and transform them
df_c <- data.frame()
files = c("concurrent_createProduct_GraphQL",
"concurrent_createProduct_REST",
"concurrent_getProductBoughtByUser_GraphQL",
"concurrent_getProductBoughtByUser_REST",
"concurrent_getUsers_REST",
"concurrent_getUsers_GraphQL")
for(file in files){
print(file)
data <- fromJSON(paste0("concurrent/",file,".json"))
data <- bind_rows(data, .id = 'concurrent_user')
data['type'] = file
df_c = rbind(df_c,data)
}
rm(data)
df_c = do.call(data.frame,df_c)
df_c = df_c %>% tidyr::separate(data = .,col = type,sep = "_",into = c("to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove"))
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:6) %>%
group_by(type, func,concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(func~type) + theme_bw()
ggplotly(p)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
#disable scientific notation
options(scipen=999)
############################################# Concurrent ##############################################################################################
#load json files and transform them
df_c <- data.frame()
files = c("concurrent_createProduct_GraphQL",
"concurrent_createProduct_REST",
"concurrent_getProductBoughtByUser_GraphQL",
"concurrent_getProductBoughtByUser_REST",
"concurrent_getUsers_REST",
"concurrent_getUsers_GraphQL")
for(file in files){
print(file)
data <- fromJSON(paste0("concurrent/",file,".json"))
data <- bind_rows(data, .id = 'concurrent_user')
data['type'] = file
df_c = rbind(df_c,data)
}
rm(data)
df_c = do.call(data.frame,df_c)
df_c = df_c %>% tidyr::separate(data = .,col = type,sep = "_",into = c("to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove"))
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:6) %>%
group_by(type, func,concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(func~type) + theme_bw()
ggplotly(p)
View(df_c)
df_c %>% filter(X2xx !== 0) %>% View
df_c %>% filter(X2xx != 0) %>% View
df_c %>% filter(X2xx != 0) %>% group_by(url, concurrent_user) %>% count()
df_c %>% filter(X2xx != 0) %>% group_by(url, concurrent_user) %>% count() %>% View
df_c %>% filter(X2xx != 0) %>% View
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
#disable scientific notation
options(scipen=999)
############################################# Concurrent ##############################################################################################
#load json files and transform them
df_c <- data.frame()
files = c("concurrent_createProduct_GraphQL",
"concurrent_createProduct_REST",
"concurrent_getProductBoughtByUser_GraphQL",
"concurrent_getProductBoughtByUser_REST",
"concurrent_getUsers_REST",
"concurrent_getUsers_GraphQL")
for(file in files){
print(file)
data <- fromJSON(paste0("concurrent/",file,".json"))
data <- bind_rows(data, .id = 'concurrent_user')
data['type'] = file
df_c = rbind(df_c,data)
}
rm(data)
df_c = do.call(data.frame,df_c)
df_c = df_c %>% tidyr::separate(data = .,col = type,sep = "_",into = c("to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove"))
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:6) %>%
group_by(type, func,concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(func~type) + theme_bw()
ggplotly(p)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
#disable scientific notation
options(scipen=999)
############################################# Concurrent ##############################################################################################
#load json files and transform them
df_c <- data.frame()
files = c("concurrent_createProduct_GraphQL",
"concurrent_createProduct_REST",
"concurrent_getProductBoughtByUser_GraphQL_mesh",
"concurrent_getProductBoughtByUser_REST",
"concurrent_getUsers_REST",
"concurrent_getUsers_GraphQL")
for(file in files){
print(file)
data <- fromJSON(paste0("concurrent/",file,".json"))
data <- bind_rows(data, .id = 'concurrent_user')
data['type'] = file
df_c = rbind(df_c,data)
}
rm(data)
df_c = do.call(data.frame,df_c)
df_c = df_c %>% tidyr::separate(data = .,col = type,sep = "_",into = c("to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove"))
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:6) %>%
group_by(type, func,concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(func~type) + theme_bw()
ggplotly(p)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
#disable scientific notation
options(scipen=999)
############################################# Concurrent ##############################################################################################
#load json files and transform them
df_c <- data.frame()
files = c("concurrent_createProduct_GraphQL",
"concurrent_createProduct_REST",
"concurrent_getProductBoughtByUser_GraphQL",
"concurrent_getProductBoughtByUser_REST",
"concurrent_getUsers_REST",
"concurrent_getUsers_GraphQL")
for(file in files){
print(file)
data <- fromJSON(paste0("concurrent/",file,".json"))
data <- bind_rows(data, .id = 'concurrent_user')
data['type'] = file
df_c = rbind(df_c,data)
}
rm(data)
df_c = do.call(data.frame,df_c)
df_c = df_c %>% tidyr::separate(data = .,col = type,sep = "_",into = c("to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove"))
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors),
timeouts = sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:6) %>%
group_by(type, func,concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(func~type) + theme_bw()
ggplotly(p)
tmp = read.csv("D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/results_productBoughtByUser_graphql_10000.csv",header=T)
View(tmp)
colnames(tmp)
tmp %>% head(10)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
tmp %>% head(10)
tmp %>% group_by(success) %>% count()
tmp %>% group_by(grpThread,success) %>% count()
tmp %>% group_by(grpThreads,success) %>% count()
tmp %>% group_by(grpThreads,success) %>% count() %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=n,fill=success)) + geom_bar(stat="identity")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% summarise(percent = round(n / sum(n)*100,digits=2) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity")
c
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% summarise(percent = round(n / sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads,success) %>% summarise(percent = round(n / sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads,success) %>% summarise(percent = round(n / sum(n)*100,digits=2)) %>% ungroup() %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n / sum(n)*100,digits=2)) %>% ungroup() %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads,success) %>% mutate(percent = round(n / sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads,success) %>% mutate(percent = round(n / sum(n)*100,digits=2)) %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n / sum(n)*100,digits=2)) %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n / sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n / sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity") + theme_bw()
p = tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n / sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity") + theme_bw()
ggplotly(p)
tmp %>% filter(success == true) %>% count()
tmp %>% filter(success == True) %>% count()
tmp %>% filter(success == "true") %>% count()
tmp %>% filter(success == "true") %>% ggplot(.,aes(x=grpThreads,y=elapsed)) + geom_boxplot()
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(.,aes(x=grpThreads,y=elapsed)) + geom_boxplot()
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(.) + geom_boxplot(aes(x=grpThreads,y=elapsed))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(.) + geom_boxplot(aes(x=grpThreads,y=elapsed,color=grpThreads))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(.) + geom_boxplot(aes(x=grpThreads,y=elapsed))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(.) + geom_boxplot(aes(x=grpThreads,y=elapsed,group=1))
class(tmp$grpThreads)
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(.) + geom_boxplot(aes(x=grpThreads,y=elapsed,group=1))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(data=.) + geom_boxplot(aes(x=grpThreads,y=elapsed,group=1))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(data=.) + geom_boxplot(aes(x=grpThreads,y=elapsed))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% ggplot(data=.) + geom_boxplot(aes(x=as.factor(grpThreads),y=elapsed))
tmp %>% filter(success == "true") %>% mutate(grpThreads = as.factor(grpThreads)) %>% ggplot(data=.) + geom_boxplot(aes(x=grpThreads,y=elapsed))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=elapsed))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed > quantile(0.99,elapsed) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed > quantile(0.99,elapsed) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed > quantile(0.99,elapsed)) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
?quantile
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed > quantile(0.95,elapsed)) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed > quantile(elapsed,0.99)) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed < quantile(elapsed,0.99, elapse > quantile(elapsed,0.01))) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed < quantile(elapsed,0.99, elapsed > quantile(elapsed,0.01))) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed < quantile(elapsed,0.99), elapsed > quantile(elapsed,0.01))) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp %>% filter(success == "true") %>% group_by(grpThreads) %>% filter(elapsed < quantile(elapsed,0.99), elapsed > quantile(elapsed,0.01)) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean))
tmp2 = read.csv("D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/results_productBoughtByUser_rest_10000.csv",header=T)
tmp["type"] = "GraphQL"
tmp2["type"] = "REST"
tmp %>% head(10)
data = rbind(tmp,tmp2)
data %>% filter(success == "true") %>% group_by(grpThreads,type) %>% filter(elapsed < quantile(elapsed,0.99), elapsed > quantile(elapsed,0.01)) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean,color=type))
data %>% filter(success == "true") %>% group_by(grpThreads,type) %>% filter(elapsed < quantile(elapsed,0.95), elapsed > quantile(elapsed,0.05)) %>% summarise(mean=mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean,color=type))
data %>% filter(success == "true") %>% group_by(failureMessage) %>% count()
data %>% filter(success == "true") %>% group_by(failureMessage,responseMessage) %>% count()
data %>% filter(success == "true") %>% group_by(grpThreads,type) %>% summarise(max = max(elapsed),min=min(elapsed))
data %>% filter(success == "true") %>% group_by(grpThreads,type) %>% summarise(max = max(elapsed),min=min(elapsed)) %>% View
data %>% filter(success == "true") %>% group_by(grpThreads,type) %>% filter(elapsed < quantile(elapsed,0.95), elapsed > quantile(elapsed,0.05)) %>% summarise(mean=max(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(data=.) + geom_line(aes(x=grpThreads,y=mean,color=type))
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
#disable scientific notation
options(scipen=999)
tmp = read.csv("D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/results_productBoughtByUser_graphql_10000.csv",header=T)
tmp %>% head(10)
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(position="dodge")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(position="dodge2")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% arrange(desc(grpThreads)) %>% head(10)
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_bar(stat="identity",position="dodge2")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_col()
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_col(position="dodge")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_area()
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = n/sum(n)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_area()
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = n/sum(n), total=sum(percent)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_area()
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2)) %>% ungroup() %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = n/sum(n), total=sum(percent)) %>% ungroup() %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2), total=sum(percent)) %>% ungroup() %>% View
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2), total=sum(percent)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_area()
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2), total=sum(percent)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_area(position=fill)
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2), total=sum(percent)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_area(position="fill")
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2), total=sum(percent)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_area(position="fill") %>% theme_bw()
tmp %>% group_by(grpThreads,success) %>% count() %>% ungroup() %>% group_by(grpThreads) %>% mutate(percent = round(n/sum(n)*100,digits=2), total=sum(percent)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,y=percent,fill=success)) + geom_area(position="fill") + theme_bw()
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
#disable scientific notation
options(scipen=999)
tmp = read.csv("D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/results_productBoughtByUser_graphql_10000.csv",header=T)
tmp %>% group_by(grpThreads,success) %>% summarise(mean = mean(grpThreads,na.rm=T)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,mean,color=success)) + geom_point()
tmp %>% group_by(grpThreads,success) %>% summarise(mean = mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,mean,color=success)) + geom_point()
tmp2 = read.csv("D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/results_productBoughtByUser_rest_10000.csv",header=T)
tmp["type"] = "GraphQL"
tmp2["type"] = "REST"
data= rbind(tmp,tmp2)
data %>% group_by(type,grpThreads,success) %>% summarise(mean = mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,mean,color=success)) + geom_point() + facet_wrap(.~type)
data %>% group_by(type,grpThreads,success) %>% summarise(mean = mean(elapsed,na.rm=T)) %>% ungroup() %>% ggplot(.,aes(x=grpThreads,mean,color=success)) + geom_point() + facet_wrap(.~type) + theme_bw()
