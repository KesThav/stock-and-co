mutate(lower_bound_threads = str_match(as.character(interval_threads),"(?<=\\()(.*)(?=,)")[,2]) %>%
filter(!is.na(lower_bound),!is.na(lower_bound_threads)) %>%
mutate(lower_bound = as.integer(lower_bound)) %>%
mutate(lower_bound_threads = as.integer(lower_bound_threads)) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("func","type"),remove = FALSE) %>%
ggplot(.)  + geom_line(aes(x=lower_bound,y=lower,color=type)) + facet_grid(func~lower_bound_threads) + theme_bw(),width = 1000,height=500)
df_c <- data.frame()
files = c("concurrent_createProduct_GraphQL",
"concurrent_createProduct_REST",
"concurrent_getProductBoughtByUser_GraphQL",
"concurrent_getProductBoughtByUser_REST",
"concurrent_getUsers_REST",
"concurrent_getUsers_GraphQL")
for(file in files){
print(file)
data <- fromJSON(paste0("concurrent/",file,".json"))
data <- bind_rows(data, .id = 'concurrent_user')
data['type'] = file
df_c = rbind(df_c,data)
}
rm(data)
df_c = do.call(data.frame,df_c)
df_c = df_c %>% tidyr::separate(data = .,col = type,sep = "_",into = c("to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
mutate(func = ifelse(func == "createProduct", "addProduct",
ifelse(func == "getProductBoughtByUser", "products-users", func)))
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
group_by(type,func,concurrent_user) %>%
summarise(X2xx = sum(X2xx),
errors = sum(errors) + sum(timeouts)) %>%
ungroup() %>%
gather("key", "value",4:5) %>%
group_by(type, func,concurrent_user) %>%
mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
ungroup() %>%
arrange(type,concurrent_user) %>%
mutate(key = ifelse(key == "X2xx", "success","failure")) %>%
ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
geom_bar(stat="identity") +
facet_grid(func~type) + theme_bw() + xlab("Concurrent user") + ylab("Percent")
ggplotly(p,width = 1000,height=500)
b = df_c %>%
filter(errors == 0) %>%
group_by(type,func, concurrent_user) %>%
filter(requests.sent == max(requests.sent)) %>%
ungroup() %>%
select(type, func, concurrent_user, requests.sent, latency.average, latency.max, latency.min, throughput.average, throughput.max, throughput.min,latency.stddev) %>%
mutate(latency.average = latency.average/1000,
latency.stddev = latency.stddev / 1000,
latency.max = latency.max / 1000,
latency.min = latency.min / 1000)
tmp = b %>% ggplot(.,aes(concurrent_user,y=latency.average,fill=type)) + geom_bar(stat="identity",position="dodge") + facet_wrap(func~.) + geom_errorbar(aes(ymin=latency.average-latency.stddev, ymax=latency.average+latency.stddev), width=.2,
position=position_dodge(.9)) + theme_bw() + xlab("Concurrent user") + ylab("Response time (second)")
ggplotly(tmp,width = 1000,height=500)
library(flexdashboard)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
library(kableExtra)
library(collapse)
library(data.table)
library(stringr)
#disable scientific notation
options(scipen=999)
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s = df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(mean_time = na.spline(mean_time),
median_time = na.spline(median_time),
max_time = na.spline(max_time),
min_time = na.spline(min_time)) %>%
ungroup()
df_s = df_s %>% mutate(func = ifelse(func == "createProduct", "addProduct",
ifelse(func == "userThatBoughtProduct", "products-users",func)))
p1 = ggplot(df_s %>% mutate(both = paste0(category, " - ", func)),aes(x=requests,y=mean_time,color=type)) + geom_line()  + facet_wrap(both~.,scales="free_y") + theme_bw() + ylab("Response time (second)") + xlab("Number of request")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s = df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(mean_time = na.spline(mean_time),
median_time = na.spline(median_time),
max_time = na.spline(max_time),
min_time = na.spline(min_time)) %>%
ungroup()
df_s = df_s %>% mutate(func = ifelse(func == "createProduct", "addProduct",
ifelse(func == "userThatBoughtProduct", "products-users",func)))
p1 = ggplot(df_s %>% mutate(both = paste0(category, " - ", func)),aes(x=requests,y=mean_time,color=type)) + geom_line()  + facet_wrap(both~.,scales="free_y") + theme_bw() + ylab("Response time (second)") + xlab("Number of request")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
View(df_s)
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
View(copy_df_s)
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T))
View(df_s)
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s = df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(mean_time = na.spline(mean_time),
median_time = na.spline(median_time),
max_time = na.spline(max_time),
min_time = na.spline(min_time)) %>%
ungroup()
df_s = df_s %>% mutate(func = ifelse(func == "createProduct", "addProduct",
ifelse(func == "userThatBoughtProduct", "products-users",func)))
p1 = ggplot(df_s %>% mutate(both = paste0(category, " - ", func)),aes(x=requests,y=mean_time,color=type)) + geom_line()  + facet_wrap(both~.,scales="free_y") + theme_bw() + ylab("Response time (second)") + xlab("Number of request")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
library(flexdashboard)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
library(kableExtra)
library(collapse)
library(data.table)
library(stringr)
#disable scientific notation
options(scipen=999)
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
approx(df_s$requests, df_s$median_time, xout = df_s$requests)$y
df_s$tmp <- approx(df_s$requests, df_s$median_time, xout = df_s$requests)$y
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% mutate(tmp = approx(requests, median_time, requests)$type)
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% mutate(tmp = approx(requests, median_time, requests)$type) %>% View
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% mutate(tmp = approx(requests, median_time, requests)$<) %>% View
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% mutate(tmp = approx(requests, median_time, requests)$y) %>% View
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()
files = c("few_data/sequential_createProduct_GraphQL",
"few_data/sequential_createProduct_REST",
"few_data/sequential_userThatBoughtProduct_GraphQL",
"few_data/sequential_userThatBoughtProduct_REST",
"few_data/sequential_getUsers_REST",
"few_data/sequential_getUsers_GraphQL",
"lot_data/sequential_createProduct_GraphQL",
"lot_data/sequential_createProduct_REST",
"lot_data/sequential_userThatBoughtProduct_GraphQL",
"lot_data/sequential_userThatBoughtProduct_REST",
"lot_data/sequential_getUsers_REST",
"lot_data/sequential_getUsers_GraphQL")
#load data and rbind everything
for(file in files){
data <- fromJSON(paste0("sequential/",file,".json"))
data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
data['type'] = file
df_s = dplyr::bind_rows(df_s,data)
}
rm(data)
#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
select(-c("to_remove")) %>%
tidyr::gather("requests","time",1:5) %>%
mutate(requests = as.integer(requests)) %>%
mutate(time = time/1000)
#create copy
copy_df_s = df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s = df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(mean_time = na.spline(mean_time),
median_time = na.spline(median_time),
max_time = na.spline(max_time),
min_time = na.spline(min_time)) %>%
ungroup()
df_s = df_s %>% mutate(func = ifelse(func == "createProduct", "addProduct",
ifelse(func == "userThatBoughtProduct", "products-users",func)))
p1 = ggplot(df_s %>% mutate(both = paste0(category, " - ", func)),aes(x=requests,y=mean_time,color=type)) + geom_line()  + facet_wrap(both~.,scales="free_y") + theme_bw() + ylab("Response time (second)") + xlab("Number of request")
ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")
df_s = copy_df_s
tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))
df_s = df_s %>%
group_by(category,func,type,requests) %>%
summarise(mean_time = mean(time,na.rm=T),
median_time = median(time,na.rm=T),
max_time = fmax(time,na.rm=T),
min_time = fmin(time,na.rm=T)) %>%
mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
) %>%
ungroup()
df_s = tmp_df %>%
left_join(df_s,by=c("category","func","type","requests")) %>%
mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
mutate(min_time = ifelse(is.nan(min_time), NA, min_time))
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% mutate(est = approxfun(x=requests, mean_time,method="linear",rule=2))
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% mutate(approxfun(x=requests, mean_time,method="linear",rule=2))
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% mutate(approxfun(x=requests, y=mean_time,method="linear",rule=2))
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>% approxfun(x=requests, y=mean_time,method="linear",rule=2)
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(estimated_mean_time = approxfun(x = unique(requests), y = unique(mean_time))(requests)) %>%
ungroup()
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(estimated_mean_time = approxfun(x = requests, y = mean_time)(requests)) %>%
ungroup()
df_s %>%
group_by(category,func,type) %>%
arrange(category,func,type,requests) %>%
mutate(estimated_mean_time = approxfun(x = requests, y = mean_time)(requests)) %>%
ungroup() %>% View
