---
title: "Benchmark analysis"
output: 
  flexdashboard::flex_dashboard:
    theme:
      bg: "#fafafa"
      fg: "#111111" 
      primary: "#116A57"
    orientation: rows
    vertical_layout: scroll
---

```{r setup, include=FALSE}
library(flexdashboard)
library(jsonlite)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyr)
library(data.table)
library(zoo)
library(kableExtra)
library(collapse)
library(data.table)
library(stringr)

#disable scientific notation
options(scipen=999)
```

```{r include=FALSE}
#prepare sequential benchmark data
#there are two categories: few_data and more_data
df_s = data.frame()

files = c("few_data/sequential_createProduct_GraphQL",
          "few_data/sequential_createProduct_REST",
          "few_data/sequential_userThatBoughtProduct_GraphQL",
          "few_data/sequential_userThatBoughtProduct_REST",
          "few_data/sequential_getUsers_REST",
          "few_data/sequential_getUsers_GraphQL",
          "lot_data/sequential_createProduct_GraphQL",
          "lot_data/sequential_createProduct_REST",
          "lot_data/sequential_userThatBoughtProduct_GraphQL",
          "lot_data/sequential_userThatBoughtProduct_REST",
          "lot_data/sequential_getUsers_REST",
          "lot_data/sequential_getUsers_GraphQL")

#load data and rbind everything
for(file in files){
  data <- fromJSON(paste0("sequential/",file,".json"))
  data <- data.table::rbindlist(list(data), fill = TRUE) %>% as.data.frame()
  data['type'] = file
  df_s = dplyr::bind_rows(df_s,data)
}

rm(data)

#split the file name and create new columns
df_s <- df_s %>% select(!starts_with('errors')) %>%
  tidyr::separate(data = .,col = type,sep = "_",into = c("category","to_remove","func","type"),remove = FALSE) %>%
  select(-c("to_remove")) %>%
  tidyr::gather("requests","time",1:5) %>%
  mutate(requests = as.integer(requests)) %>%
  mutate(time = time/1000)

#create copy 
copy_df_s = df_s
```

Sequential Benchmark
=====================================================================

Row
-------------------------------
### About the sequential Benchmark
The sequential benchmark was done in order to compare the response time of REST and GraphQL.
The test was done on two types of sample. \

The *few* sample contains : \
- 10 users
- 84 products
- 79 orders \

The *lotof* sample contains : \
- 100'000 users
- 84 products
- 300204 orders  \

We simulate a user doing n requests where n = {1,10,100,1000,10000} on three functions:\
- getUsers (only user-microservice is involved). \
- createProduct (only product-microservice is involved). \
- userThatBoughtProduct (user, product and order microservices are involved).

Row
---------------------------------------------
### Result sample size per category, function and type 

```{r, echo=FALSE}
df_s %>%
  group_by(category,func,type,requests) %>%
  summarise(n = sum(!is.na(time))) %>%
  rename(n_run = n) %>% 
  ungroup() %>%
  spread(requests, n_run) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

### Response time for getUsers and createProduct for each sample size

```{r, echo=FALSE}

tmp_df <- expand.grid(category=unique(df_s$category),func=unique(df_s$func),type=unique(df_s$type),requests=seq(1:10000))

df_s = df_s %>%
  group_by(category,func,type,requests) %>%
  summarise(mean_time = mean(time,na.rm=T),
            median_time = median(time,na.rm=T),
            max_time = fmax(time,na.rm=T),
            min_time = fmin(time,na.rm=T)) %>%
  mutate(mean_time = ifelse(is.na(mean_time) | is.nan(mean_time), lag(mean_time)*10 ,mean_time),
         median_time = ifelse(is.na(median_time) | is.nan(median_time), lag(median_time)*10 ,median_time),
         max_time = ifelse(is.na(max_time) | is.nan(max_time), lag(max_time)*10 ,max_time),
         min_time = ifelse(is.na(min_time) | is.nan(min_time), lag(min_time)*10 ,min_time)
           ) %>%
  ungroup() 

df_s = df_s %>% group_by(category, func, type) %>% mutate(mean_time = ifelse(category == "lot" & func == "userThatBoughtProduct" & requests == 1000, lag(mean_time)*10, 
                                                                             ifelse(category == "lot" & func == "userThatBoughtProduct" & requests == 10000, lag(mean_time,2)*100, mean_time)))

df_s = tmp_df %>% 
  left_join(df_s,by=c("category","func","type","requests")) %>%
  mutate(mean_time = ifelse(is.na(mean_time), NA, mean_time)) %>%
  mutate(mean_time = ifelse(is.nan(mean_time), NA, mean_time)) %>%
  mutate(median_time = ifelse(is.na(median_time), NA, median_time)) %>%
  mutate(median_time = ifelse(is.nan(median_time), NA, median_time)) %>%
  mutate(max_time = ifelse(is.na(max_time), NA, max_time)) %>%
  mutate(max_time = ifelse(is.nan(max_time), NA, max_time)) %>%
  mutate(min_time = ifelse(is.na(min_time), NA, min_time)) %>%
  mutate(min_time = ifelse(is.nan(min_time), NA, min_time))



df_s = df_s %>% 
  group_by(category,func,type) %>% 
  arrange(category,func,type,requests) %>% 
  mutate(mean_time = round(na.spline(mean_time),digit=2),
         median_time = round(na.spline(median_time),digit=2),
         max_time = round(na.spline(max_time),digit=2),
         min_time = round(na.spline(min_time),digit=2)) %>%
  ungroup()

df_s = df_s %>% mutate(func = ifelse(func == "createProduct", "addProduct",
                       ifelse(func == "userThatBoughtProduct", "products-users",func)))


p1 = ggplot(df_s %>% mutate(both = paste0(category, " - ", func)),aes(x=requests,y=mean_time,color=type)) + geom_line()  + facet_wrap(both~.,scales="free_y") + theme_bw() + ylab("Response time (second)") + xlab("Number of request")   

ggplotly(p1,width = 1000,height=500) %>% layout(hovermode = "x unified")

```

Row
-------------------------------
### Response time for getUsers and createProduct for each sample size (boxplot)
```{r, echo=FALSE}
p2 = copy_df_s %>% mutate(requests = as.factor(requests)) %>% ggplot(data=.) + geom_boxplot(aes(x=requests,y=time,color=type)) + facet_wrap(category~func,scales="free_y") + theme_bw() 

ggplotly(p2)
```


Concurrent benchmark (autocannon)
=====================================================================
```{r include=FALSE}
df_c <- data.frame()

files = c("concurrent_createProduct_GraphQL",
         "concurrent_createProduct_REST",
         "concurrent_getProductBoughtByUser_GraphQL",
         "concurrent_getProductBoughtByUser_REST",
         "concurrent_getUsers_REST",
         "concurrent_getUsers_GraphQL")



for(file in files){
  print(file)
  data <- fromJSON(paste0("concurrent/",file,".json"))
  data <- bind_rows(data, .id = 'concurrent_user')
  data['type'] = file
  df_c = rbind(df_c,data)
}

rm(data)
df_c = do.call(data.frame,df_c)

df_c = df_c %>% tidyr::separate(data = .,col = type,sep = "_",into = c("to_remove","func","type"),remove = FALSE) %>%
  select(-c("to_remove")) %>%
  mutate(func = ifelse(func == "createProduct", "addProduct", 
                       ifelse(func == "getProductBoughtByUser", "products-users", func)))
```
Row {data-height=600}
--------------------------------

### success/failure distribution

```{r, echo=FALSE}
#compute the percentage of success, errors and timeout for each concurrent user (1,10,100,1000,10000)
p = df_c %>% select("type","func","concurrent_user","X2xx","errors","timeouts") %>%
  group_by(type,func,concurrent_user) %>%
  summarise(X2xx = sum(X2xx),
            errors = sum(errors) + sum(timeouts)) %>%
  ungroup() %>%
  gather("key", "value",4:5) %>%
  group_by(type, func,concurrent_user) %>%
  mutate(percent = round(value / sum(value) * 100,digits = 2)) %>%
  ungroup() %>% 
  arrange(type,concurrent_user) %>%
  mutate(key = ifelse(key == "X2xx", "success","failure")) %>%
  ggplot(.,aes(x=concurrent_user,y=percent,fill=key)) +
  geom_bar(stat="identity") + 
  facet_grid(func~type) + theme_bw() + xlab("Concurrent user") + ylab("Percent")

ggplotly(p,width = 1000,height=500)
```

### Response time per concurrent user

```{r, echo=FALSE}

b = df_c %>% 
  filter(errors == 0) %>% 
  group_by(type,func, concurrent_user) %>% 
  filter(requests.sent == max(requests.sent)) %>%
  ungroup() %>%
  select(type, func, concurrent_user, requests.sent, latency.average, latency.max, latency.min, throughput.average, throughput.max, throughput.min,latency.stddev) %>%
  mutate(latency.average = latency.average/1000,
         latency.stddev = latency.stddev / 1000,
         latency.max = latency.max / 1000,
         latency.min = latency.min / 1000)

tmp = b %>% ggplot(.,aes(concurrent_user,y=latency.average,fill=type)) + geom_bar(stat="identity",position="dodge") + facet_wrap(func~.) + geom_errorbar(aes(ymin=latency.average-latency.stddev, ymax=latency.average+latency.stddev), width=.2,
                 position=position_dodge(.9)) + theme_bw() + xlab("Concurrent user") + ylab("Response time (second)")

ggplotly(tmp,width = 1000,height=500)
```

Concurrent benchmark (JMeter)
=====================================================================

A concurrency benchmark was done with JMeter to test server performance and response time. The sample used is the *few* sample one. The test has not been done with the *lotof* sample because response times are too high.

```{r, include=FALSE}
# path = "D:/Uni/Travail de master/apache-jmeter-5.5/a transferer/" #change this line to match your path
# files = c("addProduct_graphql",
#           "addProduct_rest",
#           "getUsers_graphql",
#           "getUsers_rest",
#           "productBoughtByUser_graphql",
#           "productBoughtByUser_rest")
# 
# df_jm = data.frame()
# 
# for(file in files) {
#   data = read.csv(paste0(path,"results_",file,"_10000.csv"),header = T)
#   data["type"] = file
#   df_jm = rbind(df_jm,data)
# }
# 
# df_jm = df_jm %>%
#   mutate(success = ifelse(success == "true", "success","failure"))
# 
# df_jm = df_jm %>% 
#   mutate(timeStamp =  as.POSIXct(timeStamp / 1000, origin = "1970-01-01"))
# 
# df_jm %>% 
# 
# rm(data)
df_jm = readRDS("df_jm.rds")
```

Row {data-height=600}
---------------------------

### Distribution of success and failure per function

```{r, echo=FALSE}
df_jm %>% 
  group_by(type,success) %>%
  count() %>%
  spread(success,n) %>%
  tidyr::separate(data = .,col = type,sep = "_",into = c("func","type"),remove = FALSE) %>%
  select(func,type,success,failure) %>%
  mutate(`success percent (%)` = round(success / (success + failure)*100,digits = 2)) %>%
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
  

```

### Distribution of response time per thread, functions and type

```{r echo=FALSE}

a = df_jm %>%
  filter(success == "success") %>%
  group_by(type,grpThreads) %>%
  summarise(mean = mean(elapsed,na.rm=T),
            median = median(elapsed,na.rm=T)) %>%
  ungroup() %>%
  tidyr::separate(data = .,col = type,sep = "_",into = c("func","type"),remove = FALSE) %>%
  rename(Threads = grpThreads) %>%
  mutate(func = ifelse(func == "createProduct", "addProduct",
                       ifelse(func == "productBoughtByUser", "products-users",func)))

ggplotly(ggplot(a,aes(x=Threads,y=mean/1000,color=type)) +
  geom_point() +
  facet_grid(.~func) + theme_bw()+ ylab("Response time (second)"),width = 1000,height=500) 
  
```

Row {data-height=600}
---------------------------

### Response time over time

```{r,echo=FALSE}

ggplotly(df_jm %>% 
           filter(success == "success") %>%
           group_by(type) %>% 
           arrange(timeStamp) %>% 
           mutate(difference = as.integer(difftime(timeStamp,first(timeStamp),units="secs"))) %>%
           mutate(interval = cut(difference,seq(0, max(difference)+10, 60),dig.lab=10)) %>%
           ungroup() %>%
           group_by(type,interval) %>% 
           summarise(response = mean(elapsed/1000,na.rm=T),n=n()) %>%
           ungroup() %>%
           mutate(lower_bound = str_match(as.character(interval),"(?<=\\()(.*)(?=,)")[,2]) %>%
           filter(!is.na(lower_bound)) %>% 
           mutate(lower_bound = as.integer(lower_bound)) %>%
           tidyr::separate(data = .,col = type,sep = "_",into = c("func","type"),remove = FALSE) %>%
           mutate(func = ifelse(func == "createProduct", "addProduct",
                       ifelse(func == "productBoughtByUser", "products-users",func))) %>%
           ggplot(.)  + geom_line(aes(x=lower_bound/60,y=response,color=type)) + facet_wrap(func~.) + theme_bw() + xlab("Time (minute)") + ylab("Response time (second)"),width = 1000,height=500)
  
  
  


```


